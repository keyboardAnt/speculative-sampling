{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/projects/dharel/nadavt/.conda/envs/jaymody-sps-env/bin/python\n",
      "Python 3.9.10\n",
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m torch.utils.collect_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/projects/dharel/nadavt/.conda/envs/jaymody-sps-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50257])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15496,    11,   616,  3290,   318, 13779]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "Outputs:\n",
      "GreedySearchDecoderOnlyOutput(sequences=tensor([[15496,    11,   616,  3290,   318, 13779,    13,   314,  1101,   407,\n",
      "          1654,   611,   673,   338,   257, 26188,   393,   407,    13,   314,\n",
      "          1101,   407,  1654,   611,   673,   338]]), scores=(tensor([[-77.4425, -80.4462, -88.0497,  ..., -96.2564, -93.6345, -84.0666]]), tensor([[-142.3193, -142.1796, -144.0388,  ..., -155.6977, -153.8760,\n",
      "         -137.7941]]), tensor([[-175.1097, -174.3555, -180.2891,  ..., -186.5559, -176.5305,\n",
      "         -176.7950]]), tensor([[-149.5665, -149.3981, -153.9603,  ..., -158.9080, -155.3729,\n",
      "         -151.3570]]), tensor([[-146.1682, -147.2101, -157.6489,  ..., -158.1571, -155.2080,\n",
      "         -150.0087]]), tensor([[-139.9639, -140.1996, -149.4295,  ..., -151.1516, -150.9630,\n",
      "         -143.5753]]), tensor([[-111.7724, -111.0601, -118.1015,  ..., -119.4616, -118.6231,\n",
      "         -113.0703]]), tensor([[-144.3919, -142.3804, -151.1539,  ..., -153.2746, -146.0314,\n",
      "         -144.4816]]), tensor([[-141.3285, -140.4888, -146.7291,  ..., -147.8345, -143.9043,\n",
      "         -142.7541]]), tensor([[-117.3899, -116.4772, -121.3259,  ..., -126.3711, -123.0911,\n",
      "         -117.4414]]), tensor([[ -98.5157,  -99.3022, -105.9519,  ..., -112.5624, -109.3629,\n",
      "         -103.0630]]), tensor([[-106.7820, -107.9948, -112.8315,  ..., -116.4186, -113.5324,\n",
      "         -107.8266]]), tensor([[-45.3371, -46.1747, -54.2727,  ..., -61.4792, -59.7055, -50.6116]]), tensor([[-162.0715, -160.2719, -162.9901,  ..., -174.5019, -174.7954,\n",
      "         -156.2698]]), tensor([[-181.4132, -180.2989, -185.5506,  ..., -191.4404, -182.3736,\n",
      "         -182.6374]]), tensor([[-157.1394, -156.6873, -161.9810,  ..., -163.8544, -162.9273,\n",
      "         -158.6824]]), tensor([[-147.5977, -148.1111, -157.4325,  ..., -156.5320, -155.3785,\n",
      "         -150.3270]]), tensor([[-135.2704, -136.3292, -145.7142,  ..., -147.2964, -147.4554,\n",
      "         -139.9985]]), tensor([[-103.0534, -102.4292, -109.0970,  ..., -110.2150, -109.6744,\n",
      "         -104.7673]]), tensor([[-124.7625, -123.2115, -130.5318,  ..., -134.2353, -126.6790,\n",
      "         -125.2399]])), attentions=None, hidden_states=None)\n",
      "====\n",
      "transition_scores:\n",
      "tensor([[-1.2596, -1.5887, -1.9783, -2.1347, -1.2013, -1.2065, -1.4077, -1.2406,\n",
      "         -2.4125, -2.8545, -0.5006, -0.9584, -1.1055, -1.3975, -1.6479, -1.7748,\n",
      "         -0.2831, -0.6819, -0.3247, -0.6229]])\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=20, return_dict_in_generate=True, output_scores=True, do_sample=False)\n",
    "print(\"====\")\n",
    "print(\"Outputs:\")\n",
    "print(outputs)\n",
    "print(\"====\")\n",
    "transition_scores = model.compute_transition_scores(\n",
    "    outputs.sequences, outputs.scores, normalize_logits=True\n",
    ")\n",
    "print(\"transition_scores:\")\n",
    "print(transition_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--type <class 'str'> is not supported\n",
      "--torch.Size([3])\n",
      "--key\n",
      "----torch.Size([3])\n",
      "====\n",
      "type <class 'str'> is not supported\n",
      "====\n",
      "--type <class 'int'> is not supported\n",
      "--type <class 'int'> is not supported\n",
      "--torch.Size([3])\n",
      "--nested\n",
      "------torch.Size([3])\n",
      "------type <class 'str'> is not supported\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "from torch import Tensor\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "def print_shapes(obj: Any, level: int = 0):\n",
    "    padding = \"--\" * level\n",
    "    \n",
    "    if isinstance(obj, Tensor):\n",
    "        print(f\"{padding}{obj.shape}\")\n",
    "    elif isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            print(f\"{padding}{k}\")\n",
    "            print_shapes(v, level + 1)\n",
    "    elif isinstance(obj, str):\n",
    "        print(f\"{padding}type {type(obj)} is not supported\")\n",
    "    elif isinstance(obj, Iterable):\n",
    "        for x in obj:\n",
    "            print_shapes(x, level + 1)\n",
    "    else:\n",
    "        print(f\"{padding}type {type(obj)} is not supported\")\n",
    "\n",
    "\n",
    "# Test cases\n",
    "print_shapes([\"test\", Tensor([1, 2, 3]), {\"key\": Tensor([4, 5, 6])}])\n",
    "print(\"====\")\n",
    "print_shapes(\"This is a string\")\n",
    "print(\"====\")\n",
    "print_shapes((1, 2, Tensor([7, 8, 9]), {\"nested\": [Tensor([10, 11, 12]), \"string\"]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences\n",
      "--torch.Size([1, 26])\n",
      "scores\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n",
      "----torch.Size([1, 50257])\n"
     ]
    }
   ],
   "source": [
    "print_shapes(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs.scores), len(outputs.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50257])\n",
      "tensor(-156.0660)\n",
      "tensor(-112.9710)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.scores[-1].shape)\n",
    "print(outputs.scores[-1].min())\n",
    "print(outputs.scores[-1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaymody-sps-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
